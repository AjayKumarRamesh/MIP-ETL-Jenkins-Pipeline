pipeline {
    agent { label 'kube_pod_slave' }
    environment {
       IMAGE = ''                               //can be used in whole pipeline
       APP_JAR = ''
       DAG_ID = "${DAG_NAME}"
       SOURCE_CODE_FOLDER = ''
    }
    stages {
        stage('GitHub Checkout') {
            steps {
                git credentialsId: 'sangita_id_rsa' ,
                url: 'ssh://git@github.ibm.com/CIO-MAP/Jenkins_Poc_mapetl.git', branch: 'master'  
            }  //steps
        } //stage
        stage('SonarQube Analysis') {
            agent { label 'taas_image' }
            environment{
                //SonarQube Scanner plugin base home path 
                scannerBaseHome = "${HOME}/scannerBaseHome"
                //SonarQube Scanner plugin home - based on the scanner version
                SCANNER_HOME = "${scannerBaseHome}/sonar-scanner-4.7.0.2747-linux"
                //SonarQube Scanner additional options - we pass the turststore and password required to connect to SonarQube server
                SONAR_SCANNER_OPTS = "-Djavax.net.ssl.trustStore=${HOME}/cacerts -Djavax.net.ssl.trustStorePassword=changeit -Dsonar.issuesReport.html.enable=true"
                //SonarQube server URL
                SONAR_HOST_URL = "https://sms-sonarqube-intranet.dal1a.cirrus.ibm.com/"
                //Java home required to run the sonar-scanner
                JAVA_HOME = "/usr/lib/jvm/java-11-openjdk-amd64"
                PATH = "${JAVA_HOME}/bin/:${PATH}"
                //SonarQube Project Name - replace <sonar_project> from the list of projects eg. MAP-ETL-Framework
                SONAR_PROJECT_NAME="MIP-ETL-Jenkins-Pipeline"
                //SonarQube Project Key - replace <sonar_key> with the project name eg. MAP-ETL-Framework
                SONAR_PROJECT_KEY="MIP-ETL-Jenkins-Pipeline"
                //File or folders than need to be excluded from scans
                SONAR_EXCLUSIONS="**/*.java"
                //SONAR_EXCLUSIONS=""
            }
            steps {
                script {
                    // Prepare truststore
                    withCredentials([file(credentialsId: 'ibm_sonar_enterprise_cert', variable: 'FILE')]){
                        sh ("keytool -importcert -keystore ${HOME}/cacerts -storepass changeit -file $FILE -alias 'ibm_sonar' -noprompt -trustcacerts")
                    }
                    def scannerHome = tool 'sonar-scanner';
                    withSonarQubeEnv('SonarQube'){
                        sh ("${scannerHome}/bin/sonar-scanner -Dsonar.projectName=${SONAR_PROJECT_NAME} -Dsonar.projectKey=${SONAR_PROJECT_KEY} -Dsonar.exclusions=${SONAR_EXCLUSIONS}")
                    }

                    // Quality Gate Check
                    echo "checking the quality Gate"
                    def tries = 0
                    sonarResultStatus = "PENDING"
                    while ((sonarResultStatus == "PENDING" || sonarResultStatus == "IN_PROGRESS") && tries++ < 5) {
                        try {
                            timeout(time: 1, unit: 'MINUTES') {
                                sonarResult = waitForQualityGate abortPipeline: true
                                sonarResultStatus = sonarResult.status
                            }
                        } catch(ex) {
                            echo "caught exception ${ex}"
                        }
                        echo "waitForQualityGate status is ${sonarResultStatus} (tries=${tries})"
                    }
                    if (sonarResultStatus != 'OK') {
                        error "Quality gate failure for SonarQube: ${sonarResultStatus}"
                    }
                } //script
            }
        }
        stage('Get Global Vars') {
            steps{
                script {
                    def JENKINS_FUNC = load "./jenkins_files/test/JenkinsFunctions.groovy"
                    (IMAGE, APP_JAR, SOURCE_CODE_FOLDER) = JENKINS_FUNC.getGlobalVars(DAG_ID)
                    IMAGE = IMAGE + ":${env.BUILD_NUMBER}"
                }
            }
        }
        stage('Flare ETL Framework download and Maven build'){
            environment {
                GITHUB_API_TOKEN = credentials('github_api_token')
                GITHUB_ETL_URL = "https://github.ibm.com/api/v3/repos/CIO-Mkt-DataEng/Flare/releases/assets/750716"
                OUTPUT_FILENAME = "Flare-v2.1-Log4j2.jar"
            }
            steps{
                dir("sourcecode/${SOURCE_CODE_FOLDER}") {
                    sh "pwd"
                
                    sh 'curl -L -H "Authorization: token $GITHUB_API_TOKEN" -H "Accept:application/octet-stream" "$GITHUB_ETL_URL" -o $OUTPUT_FILENAME'
                    sh 'ls -al'

                    sh 'mvn -version'
                    sh 'ls -al'
                    sh 'mvn install:install-file -Dfile=Flare-v2.1-Log4j2.jar -DgroupId=com.flare -DartifactId=base -Dversion=2.1-Log4j2 -Dpackaging=jar'
                    script {
                        def JENKINS_FUNC = load "./../../jenkins_files/test/JenkinsFunctions.groovy"
                        JENKINS_FUNC.mavenBuild()
                    }
                }
            }
        }
        stage('Get COS Objects') {
            environment {
                IBMCLOUD_CREDS = credentials('ibm-cloud-cr')
                IBMCLOUD_COS_CRN = 'bda9a48c-574e-4be0-b2ff-62f2d0f23ead'
                IBMCLOUD_COS_REGION = 'ap-geo'
                IBMCLOUD_COS_BUCKET = 'map-dev-01'
            }
 
            steps{
                dir("sourcecode/${SOURCE_CODE_FOLDER}") {
                    sh "pwd"
                    script {
                        def JENKINS_FUNC = load "./../../jenkins_files/test/JenkinsFunctions.groovy"
                        JENKINS_FUNC.cloudLogin(IBMCLOUD_CREDS_PSW, "dev", true)
                        JENKINS_FUNC.getCOSObjects(IBMCLOUD_CREDS, IBMCLOUD_COS_CRN, 
                                                   IBMCLOUD_COS_REGION, IBMCLOUD_COS_BUCKET, DAG_ID)
                    }

                }
            }
        }
        
        stage('Image build') {
            environment {
                IBMCLOUD_CREDS = credentials('ibm-cloud-cr')
            }

            steps {
                dir("sourcecode/${SOURCE_CODE_FOLDER}") {
                    sh "pwd"
                
                    //sh "ibmcloud plugin install container-registry"
                    sh "ibmcloud plugin list"
                    sh "ibmcloud login --apikey ${IBMCLOUD_CREDS_PSW} -r us-south"
                    sh "ibmcloud cr login"
                    sh "docker build -t us.icr.io/map-dev-namespace/${IMAGE} -f spark-3.0.1-bin-hadoop2.7/Dockerfile ./spark-3.0.1-bin-hadoop2.7"
                    sh "docker images"
                    sh "docker push us.icr.io/map-dev-namespace/${IMAGE}"
                    sh "ibmcloud cr image-list --restrict 'map-dev-namespace'"
                }
            }
        } //stage
        
        stage('Sign and push Dev Image') {
            agent { label 'code-signing-agent' }
            environment {
                CERTIFICATE_ALIAS = 'IBMCodeSignCert1221'
                DAG_LOWER = DAG_NAME.toLowerCase()
                PUBLIC_KEY_FILE = "/tmp/${CERTIFICATE_ALIAS}-key.pub"
                PFX_FILE = credentials('signing-pfx-file')
                IBMCLOUD_CREDS = credentials('ibm-cloud-cr')
                IMAGE_BUILD_TAG="us.icr.io/map-dev-namespace/${DAG_LOWER}:${BUILD_NUMBER}"
                IMAGE_RELEASE_TAG="us.icr.io/map-dev-namespace/${DAG_LOWER}:signed"
            }
            steps {
                echo '\n=== Preparing the Environment for Image Signing ==='
                // Inject the PFX file to the required location
                echo '\nInjecting the PFX file...'
                sh '''
                chmod 644 ${PFX_FILE}
                sudo cp ${PFX_FILE} /etc/ekm
                '''

                // Configure local PGP keys for use in signing
                echo '\nConfigure local PGP keys for use in signing'
                sh '''
                    # Download local 'pointer keys' referencing the actual private and public keys stored in the HSM (Hardware Security Module)
                    sudo ucl pgp-key -n ${CERTIFICATE_ALIAS}
                    # Export our public key to be used for image verification
                    sudo gpg2 --armor --output ${PUBLIC_KEY_FILE} --export ${CERTIFICATE_ALIAS}
                '''

                // Signing and Publishing the Image
                echo '\n=== Signing and Publishing the Image ==='
                sh '''
                    docker images
                    FINGERPRINT=$(sudo gpg2 --no-tty --batch --fingerprint --with-colons "${CERTIFICATE_ALIAS}" | grep '^fpr' | cut -d : -f 10 | head -n 1)
                    LOCAL_DAEMON=$(echo ${DOCKER_HOST} | sed s/tcp/http/)
                    sudo skopeo copy \
                        --dest-creds iamapikey:${IBMCLOUD_CREDS_PSW} \
                        --remove-signatures \
                        --sign-by ${FINGERPRINT} \
                        --src-daemon-host "${LOCAL_DAEMON}" \
                        docker-daemon:${IMAGE_BUILD_TAG} \
                        docker://${IMAGE_RELEASE_TAG}
                '''
            } //steps
        } //stage
        
        stage('Image deploy to Airflow') {
            environment {
                IBMCLOUD_CREDS = credentials('ibm-cloud-cr')
            }

            steps {
                script {
                    def JENKINS_FUNC = load "./jenkins_files/test/JenkinsFunctions.groovy"
                    JENKINS_FUNC.cloudLogin(IBMCLOUD_CREDS_PSW, "dev", false)
                    AIRFLOW_POD = sh(script:'kubectl get pods -n airflow --no-headers -o custom-columns=":metadata.name" | grep airflow-scheduler', returnStdout: true).trim()
                    //def (image, jar) = JENKINS_FUNC.getAirflowVars(AIRFLOW_POD, DAG_ID)
                    JENKINS_FUNC.setAirflowVars(AIRFLOW_POD, DAG_ID, IMAGE, APP_JAR)
                    def (image, jar) = JENKINS_FUNC.getAirflowVars(AIRFLOW_POD, DAG_ID)
                    sh "echo '${image} ${jar}'"
                }
            }
        }  //stage
    } //stages
} //pipeline

