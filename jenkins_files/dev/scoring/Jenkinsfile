pipeline {
    agent any
    environment {
       IMAGE = "spss_scoring:${env.BUILD_NUMBER}"                    //can be used in whole pipeline
       APP_JAR = 'com.ibm.map-SpssScoring-2.2.jar'
       DAG_ID = "MIP_SPSS_SCORING"
       SOURCE_CODE_FOLDER = "scoring"
    }
    stages {
           stage('GitHub Checkout') {
               steps {
                git credentialsId: 'sangita_id_rsa' ,
                url: 'ssh://git@github.ibm.com/CIO-MAP/Jenkins_Poc_mapetl.git', branch: 'master'  
               }  //steps
           } //stage

           stage('Get COS Objects') {
               environment {
                   IBMCLOUD_CREDS = credentials('ibm-cloud-cr')
                   IBMCLOUD_COS_CRN = 'bda9a48c-574e-4be0-b2ff-62f2d0f23ead'
                   IBMCLOUD_COS_REGION = 'ap-geo'
                   IBMCLOUD_COS_BUCKET = 'map-dev-01'
               }
                steps{
                               dir("sourcecode/${SOURCE_CODE_FOLDER}") {
                                   sh "pwd"
                                   script {
                                       def JENKINS_FUNC = load "./../../jenkins_files/test/JenkinsFunctions.groovy"
                                       JENKINS_FUNC.cloudLogin(IBMCLOUD_CREDS_PSW, "dev", true)
                                       JENKINS_FUNC.getCOSObjects(IBMCLOUD_CREDS, IBMCLOUD_COS_CRN,
                                                                  IBMCLOUD_COS_REGION, IBMCLOUD_COS_BUCKET, DAG_ID)
                                   }

                               }
                           }
               }



           stage('Flare ETL Framework download and Maven build'){
                       environment {
                           GITHUB_API_TOKEN = credentials('github_api_token')
                           GITHUB_ETL_URL = "https://github.ibm.com/api/v3/repos/CIO-Mkt-DataEng/Flare/releases/assets/786093"
                           OUTPUT_FILENAME = "Flare-v2.1-Log4j2.jar"
                       }
                       steps{
                           dir("sourcecode/${SOURCE_CODE_FOLDER}") {
                               sh "pwd"

                               sh 'curl -L -H "Authorization: token $GITHUB_API_TOKEN" -H "Accept:application/octet-stream" "$GITHUB_ETL_URL" -o $OUTPUT_FILENAME'
                               sh 'ls -al'

                               sh 'mvn -version'
                               sh 'ls -al'
                               sh 'mvn install:install-file -Dfile=Flare-v2.1-Log4j2.jar -DgroupId=com.flare -DartifactId=base -Dversion=2.1-Log4j2 -Dpackaging=jar'
                               script {
                                   def JENKINS_FUNC = load "./../../jenkins_files/test/JenkinsFunctions.groovy"
                                   JENKINS_FUNC.mavenBuild()
                               }
                           }
                       }
                   }

           stage('Image build') {
                  environment {
                      IBMCLOUD_CREDS = credentials('ibm-cloud-cr')
                  }

                  steps {
                      dir("sourcecode/${SOURCE_CODE_FOLDER}") {
                          sh "pwd"

                          //sh "ibmcloud plugin install container-registry"
                          sh "ibmcloud plugin list"
                          sh "ibmcloud login --apikey ${IBMCLOUD_CREDS_PSW} -r us-south"
                          sh "ibmcloud cr login"
                          sh "docker build -t us.icr.io/map-dev-namespace/${IMAGE} -f spark-3.0.1-bin-hadoop2.7/Dockerfile ./spark-3.0.1-bin-hadoop2.7"
                          sh "docker images"
                          //sh "docker push us.icr.io/map-dev-namespace/${IMAGE}"
                          //sh "ibmcloud cr image-list --restrict 'map-dev-namespace'"
                      }
                  }
           } //stage

           stage('Sign and push Dev Image') {
                agent { label 'code-signing-agent' }
                environment {
                    CERTIFICATE_ALIAS = 'IBMCodeSignCert1221'
                    // = DAG_NAME.toLowerCase()
                    PUBLIC_KEY_FILE = "/tmp/${CERTIFICATE_ALIAS}-key.pub"
                    PFX_FILE = credentials('signing-pfx-file')
                    IBMCLOUD_CREDS = credentials('ibm-cloud-cr')
                    IMAGE_BUILD_TAG="us.icr.io/map-dev-namespace/${IMAGE}"
                    IMAGE_RELEASE_TAG="us.icr.io/map-dev-namespace/${IMAGE}"
                }
                steps {
                    echo '\n=== Preparing the Environment for Image Signing ==='
                    // Inject the PFX file to the required location
                    echo '\nInjecting the PFX file...'
                    sh '''
                    chmod 644 ${PFX_FILE}
                    sudo cp ${PFX_FILE} /etc/ekm
                    '''

                    // Configure local PGP keys for use in signing
                    echo '\nConfigure local PGP keys for use in signing'
                    sh '''
                        # Download local 'pointer keys' referencing the actual private and public keys stored in the HSM (Hardware Security Module)
                        sudo ucl pgp-key -n ${CERTIFICATE_ALIAS}
                        # Export our public key to be used for image verification
                        sudo gpg2 --armor --output ${PUBLIC_KEY_FILE} --export ${CERTIFICATE_ALIAS}
                    '''

                    // Signing and Publishing the Image
                    echo '\n=== Signing and Publishing the Image ==='
                    sh '''
                        docker images
                        FINGERPRINT=$(sudo gpg2 --no-tty --batch --fingerprint --with-colons "${CERTIFICATE_ALIAS}" | grep '^fpr' | cut -d : -f 10 | head -n 1)
                        LOCAL_DAEMON=$(echo ${DOCKER_HOST} | sed s/tcp/http/)
                        sudo skopeo copy \
                            --dest-creds iamapikey:${IBMCLOUD_CREDS_PSW} \
                            --remove-signatures \
                            --sign-by ${FINGERPRINT} \
                            --src-daemon-host "${LOCAL_DAEMON}" \
                            docker-daemon:${IMAGE_BUILD_TAG} \
                            docker://${IMAGE_RELEASE_TAG}
                    '''
            } //steps
        } //stage
        
           stage('Image deploy to Airflow') {
                  environment {
                        IBMCLOUD_CREDS = credentials('ibm-cloud-cr')
                  }

                steps {
                    script {
                        def JENKINS_FUNC = load "./jenkins_files/test/JenkinsFunctions.groovy"
                        JENKINS_FUNC.cloudLogin(IBMCLOUD_CREDS_PSW, "dev", false)
                        AIRFLOW_POD = sh(script:'kubectl get pods -n airflow --no-headers -o custom-columns=":metadata.name" | grep airflow-scheduler', returnStdout: true).trim()
                        //def (image, jar) = JENKINS_FUNC.getAirflowVars(AIRFLOW_POD, DAG_ID)
                        JENKINS_FUNC.setAirflowVars(AIRFLOW_POD, DAG_ID, IMAGE, APP_JAR)
                        def (image, jar) = JENKINS_FUNC.getAirflowVars(AIRFLOW_POD, DAG_ID)
                        sh "echo '${image} ${jar}'"
                    }
                }
           }  //stage
    } //stages
} //pipeline

